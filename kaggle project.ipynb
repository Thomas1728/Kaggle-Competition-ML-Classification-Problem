{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mltools as ml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(r'D:\\cs178\\final_project\\uci-cs178-win21/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt(r'D:\\cs178\\final_project\\uci-cs178-win21/Y_train.txt', delimiter=None)\n",
    "Xte = np.genfromtxt(r'D:\\cs178\\final_project\\uci-cs178-win21/X_test.txt', delimiter=None)\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y) # Default is 80% training/20% validation\n",
    "Xtr, Ytr = ml.shuffleData(Xtr, Ytr)\n",
    "\n",
    "#XtrP, params = ml.rescale(Xtr)\n",
    "#XteP, _ = ml.rescale(Xte, params)\n",
    "#XvaP, _ = ml.rescale(Xva, params)\n",
    "scaler = preprocessing.StandardScaler().fit(Xtr)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xva = scaler.transform(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 1 : Jsur = 0.4343540390430482, J01 = 0.3436125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\cs178\\final_project\\mltools\\nnet.py:218: RuntimeWarning: overflow encountered in exp\n",
      "  self.Sig = lambda z: twod(1 / (1 + np.exp(-z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 2 : Jsur = 0.43437075859111474, J01 = 0.3436125\n",
      "it 4 : Jsur = 0.43389466978030294, J01 = 0.3436125\n",
      "it 8 : Jsur = 0.432993038283083, J01 = 0.3436125\n",
      "it 16 : Jsur = 0.4319243378010827, J01 = 0.3436125\n",
      "it 32 : Jsur = 0.43114126469908204, J01 = 0.3436125\n"
     ]
    }
   ],
   "source": [
    "nn = ml.nnet.nnetClassify()\n",
    "nn.setActivation('logistic')\n",
    "nn.init_weights([Xtr.shape[1], 20, len(np.unique(Ytr))], 'random', Xtr, Ytr)\n",
    "nn.train(Xtr, Ytr, stopTol=1e-5, stepsize=.2, stopIter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc: 0.6494225154264011\n",
      "validation auc: 0.6525623770447198\n"
     ]
    }
   ],
   "source": [
    "print(f'training auc: {nn.auc(Xtr, Ytr)}')\n",
    "print(f'validation auc: {nn.auc(Xva, Yva)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7821989740288865\n"
     ]
    }
   ],
   "source": [
    "#Second best\n",
    "GB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.32, max_depth=12)\n",
    "GB.fit(Xtr, Ytr)\n",
    "\n",
    "GB_pred = GB.predict_proba(Xva)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, GB_pred)\n",
    "print(metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GB = GradientBoostingClassifier(n_estimators=120, learning_rate=0.32, max_depth=12).fit(X, Y)\n",
    "GB_pred_final = GB.predict_proba(Xte)[:, 1:2]\n",
    "Y_sub = np.vstack((np.arange(Xte.shape[0]), GB_pred_final[:, 0])).T\n",
    "\n",
    "np.savetxt('Y_submit.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799249852108798\n"
     ]
    }
   ],
   "source": [
    "#advanced gradient boosting\n",
    "XB = XGBClassifier(n_estimators=135, max_depth=12, learning_rate=0.3, reg_alpha = 8).fit(Xtr, Ytr)\n",
    "\n",
    "XB_pred = XB.predict_proba(Xva)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, XB_pred)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "XB = XGBClassifier(n_estimators=135, max_depth=12, learning_rate=0.3, reg_alpha = 8).fit(X, Y)\n",
    "XB_pred_final = XB.predict_proba(Xte)[:, 1:2]\n",
    "Y_sub = np.vstack((np.arange(Xte.shape[0]), XB_pred_final[:, 0])).T\n",
    "\n",
    "np.savetxt('Y_submit.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6921498333731135\n"
     ]
    }
   ],
   "source": [
    "AdaBoosting = AdaBoostClassifier(n_estimators=145, learning_rate=1.5, random_state=0, algorithm = \"SAMME.R\").fit(Xtr, Ytr)\n",
    "Ada_pred = AdaBoosting.predict_proba(Xva)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, Ada_pred)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7922617350213166\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(n_estimators=145, max_depth= 28, criterion = \"entropy\", min_samples_leaf = 4, max_features = 2).fit(Xtr, Ytr)\n",
    "RF_pred = RandomForest.predict_proba(Xva)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, RF_pred)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8010028296701845\n"
     ]
    }
   ],
   "source": [
    "#best choice by now\n",
    "bagging = BaggingClassifier(n_estimators = 135, n_jobs = -1, max_features = 4).fit(Xtr, Ytr)\n",
    "bagging_pred = bagging.predict_proba(Xva)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, bagging_pred)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bagging = BaggingClassifier(n_estimators = 135, n_jobs = -1, max_features = 4).fit(X, Y)\n",
    "bagging_pred_final = bagging.predict_proba(Xte)[:, 1:2]\n",
    "Y_sub = np.vstack((np.arange(Xte.shape[0]), bagging_pred_final[:, 0])).T\n",
    "\n",
    "np.savetxt('Y_submit.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108224648598269\n"
     ]
    }
   ],
   "source": [
    "weight = [5, 2.5, 7.4]\n",
    "combined_pred = []\n",
    "for i in range(len(RF_pred)):\n",
    "    combined_pred.append((weight[0] * XB_pred[i] + weight[1] * RF_pred[i] + weight[2] * bagging_pred[i])/ sum(weight))\n",
    "    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yva, combined_pred)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "XB = XGBClassifier(n_estimators=135, max_depth=12, learning_rate=0.3, reg_alpha = 8).fit(X, Y)\n",
    "RandomForest = RandomForestClassifier(n_estimators=145, max_depth= 28, criterion = \"entropy\", min_samples_leaf = 4, max_features = 2).fit(X, Y)\n",
    "bagging = BaggingClassifier(n_estimators = 135, n_jobs = -1, max_features = 4).fit(X, Y)\n",
    "\n",
    "bagging_pred_final = bagging.predict_proba(Xte)[:, 1:2]\n",
    "XB_pred_final = XB.predict_proba(Xte)[:, 1:2]\n",
    "RF_pred_final = RandomForest.predict_proba(Xte)[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [5, 2.5, 7.4]\n",
    "#weight = [7.4, 3, 10.5] second best\n",
    "combined_pred = []\n",
    "for i in range(len(bagging_pred_final)):\n",
    "    combined_pred.append((weight[0] * XB_pred_final[i] + weight[1] * RF_pred_final[i] + weight[2] * bagging_pred_final[i])/ sum(weight))\n",
    "\n",
    "    \n",
    "Y_sub = np.vstack((np.arange(Xte.shape[0]), np.array(combined_pred)[:, 0])).T\n",
    "np.savetxt('Y_submit.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
